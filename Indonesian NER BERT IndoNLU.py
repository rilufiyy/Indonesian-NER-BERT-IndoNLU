# -*- coding: utf-8 -*-
"""Sri Lutfiya Dwiyeni_Mini Project Day 38_NLP_AIML 8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TmOZl6s4dxnlJYHfzIPZtPLNBzrZhtYM

# Problem Understanding

### Apa itu Named Entity Recognition (NER)?

NER adalah tugas dalam NLP untuk mengidentifikasi dan mengklasifikasikan entitas bernama dalam teks.

Pada proyek ini, saya mengerjakan task Named Entity Recognition (NER) untuk Bahasa Indonesia. Tujuan utama dari NER adalah mengidentifikasi dan mengklasifikasikan entitas penting dalam teks, seperti Person, Location, Organization, dan Date. Task ini penting karena menjadi fondasi bagi banyak aplikasi NLP lanjutan, seperti information extraction, question answering, dan text analytics.

# Import Libraries
"""

!pip install -q transformers datasets seqeval accelerate
!pip install -q scikit-learn matplotlib seaborn pandas numpy

!pip install -U transformers accelerate

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter, defaultdict
import warnings
warnings.filterwarnings("ignore")

from transformers import (
    AutoTokenizer,
    AutoModelForTokenClassification,
    TrainingArguments,
    Trainer,
    DataCollatorForTokenClassification
)
from datasets import Dataset, DatasetDict
from seqeval.metrics import classification_report, precision_score, recall_score, f1_score
from seqeval.scheme import IOB2
from transformers import EarlyStoppingCallback

SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)

sns.set_style("whitegrid")
plt.rcParams["figure.figsize"] = (12,6)

"""# Load Dataset

**Catatan:** Dataset yang saya gunakan adalah dataset IndoNLU yang diambil dari link: https://github.com/IndoNLP/indonlu
, khususnya sub-dataset nerp_ner-prosa yang digunakan untuk tugas Named Entity Recognition (NER) pada teks berbahasa Indonesia, dengan tujuan mengenali entitas seperti orang (PER), lokasi (LOC), organisasi (ORG), dan tanggal (DATE).
"""

!git clone https://github.com/IndoNLP/indonlu.git

!ls

!ls indonlu

!ls indonlu/dataset

!ls indonlu/dataset/nerp_ner-prosa

def read_conll(path):
    sentences, labels = [], []
    sentence, label = [], []

    with open(path, encoding="utf-8") as f:
        for line in f:
            line = line.strip()

            if not line:
                if sentence:
                    sentences.append(sentence)
                    labels.append(label)
                    sentence, label = [], []
            else:
                parts = line.split()
                token = parts[0]
                tag = parts[-1]

                sentence.append(token)
                label.append(tag)

    return sentences, labels

base_path = "indonlu/dataset/nerp_ner-prosa"

train_texts, train_labels = read_conll(f"{base_path}/train_preprocess.txt")
val_texts, val_labels     = read_conll(f"{base_path}/valid_preprocess.txt")
test_texts, test_labels   = read_conll(f"{base_path}/test_preprocess.txt")

print(train_texts[0])
print(train_labels[0])

all_labels = set()
for labels in train_labels + val_labels + test_labels:
    all_labels.update(labels)

label_list = sorted(list(all_labels))
label2id = {label: i for i, label in enumerate(label_list)}
id2label = {i: label for label, i in label2id.items()}

print(label_list)
print("Jumlah label:", len(label_list))

print("Jumlah kalimat pada dataset:")
print(f"Train      : {len(train_texts)}")
print(f"Validation : {len(val_texts)}")
print(f"Test       : {len(test_texts)}")
print(f"Total      : {len(train_texts) + len(val_texts) + len(test_texts)}")

"""## Data Understanding

Dataset yang digunakan dalam penelitian ini merupakan dataset Named Entity Recognition (NER) Bahasa Indonesia dari IndoNLU, khususnya subset NER Prosa, yang bersumber dari artikel berita daring berbahasa Indonesia. Seluruh data bersifat publik dan tidak mengandung informasi pribadi sensitif, sehingga aman digunakan dari sisi keamanan data dan privasi.

Dataset ini bertujuan untuk melatih model dalam mengenali dan mengklasifikasikan entitas bernama pada teks berita Bahasa Indonesia. Setiap token dalam kalimat telah dianotasi secara manual menggunakan skema BIO (Begin–Inside–Outside) untuk menandai batas dan jenis entitas.

### Jenis Entitas

| Label    | Deskripsi                                                             |
| -------- | --------------------------------------------------------------------- |
| **PER**  | Nama individu atau tokoh (misalnya nama pejabat, atlet, publik figur) |
| **LOC**  | Nama lokasi geografis seperti kota, provinsi, atau negara             |
| **ORG**  | Nama organisasi, institusi, perusahaan, atau lembaga                  |
| **DATE** | Informasi waktu atau tanggal kejadian                                 |

### Skema BIO Tagging

Dataset menggunakan skema BIO (Beginning–Inside–Outside) untuk menandai entitas pada tingkat token. Skema ini memungkinkan model untuk memahami batas awal dan kelanjutan entitas multi-token.

| Tag                                | Keterangan                                |
| ---------------------------------- | ----------------------------------------- |
| **B-PER / B-LOC / B-ORG / B-DATE** | Token pertama dari suatu entitas          |
| **I-PER / I-LOC / I-ORG / I-DATE** | Token lanjutan dari entitas yang sama     |
| **O**                              | Token yang tidak termasuk entitas apa pun |

# Data Preprocessing
"""

train_labels_original = [seq.copy() for seq in train_labels]
val_labels_original   = [seq.copy() for seq in val_labels]
test_labels_original  = [seq.copy() for seq in test_labels]

label_mapping = {
    "B-PPL": "B-PER", "I-PPL": "I-PER",
    "B-PLC": "B-LOC", "I-PLC": "I-LOC",
    "B-IND": "B-ORG", "I-IND": "I-ORG",
    "B-EVT": "B-DATE", "I-EVT": "I-DATE",
    "B-FNB": "O",     "I-FNB": "O",
    "O": "O"
}

def remap_labels(label_sequences):
    return [
        [label_mapping.get(label, label) for label in seq]
        for seq in label_sequences
    ]

train_labels = remap_labels(train_labels)
val_labels   = remap_labels(val_labels)
test_labels  = remap_labels(test_labels)

for name, labels in {
    "train": train_labels,
    "val": val_labels,
    "test": test_labels
}.items():
    uniq = sorted(set(l for seq in labels for l in seq))
    print(name, uniq)

label_list = sorted(set(l for seq in train_labels for l in seq))

label2id = {label: i for i, label in enumerate(label_list)}
id2label = {i: label for label, i in label2id.items()}

print(train_labels[0])

idx = 0

print("Kalimat:")
print(train_texts[idx])

print("\nLabel asli (sebelum mapping):")
print(train_labels_original[idx])

print("\nLabel setelah mapping:")
print(train_labels[idx])

"""| Label Dataset | Diubah ke | Alasan                                  |
| ------------- | --------- | --------------------------------------- |
| **PPL**       | **PER**   | Sama-sama entitas orang                 |
| **PLC**       | **LOC**   | Sama-sama lokasi                        |
| **IND**       | **ORG**   | Industri → organisasi/bidang            |
| **FNB**       | **ORG**   | Brand makanan/minuman = organisasi      |
| **EVT**       | **DATE**  | Event biasanya berkaitan waktu kejadian |
"""

for token, lbl_before, lbl_after in zip(
    train_texts[idx],
    train_labels_original[idx],
    train_labels[idx]
):
    print(f"{token:15} {lbl_before:10} → {lbl_after}")

all_mapped_labels = set(
    l for sent in train_labels for l in sent
)

print("Label unik setelah mapping:")
print(sorted(all_mapped_labels))
print("Jumlah label:", len(all_mapped_labels))

"""# Exploratory Data Analysis (EDA)"""

label_counter = Counter(l for s in train_labels for l in s)

plt.figure()
sns.barplot(x=list(label_counter.keys()), y=list(label_counter.values()))
plt.xticks(rotation=90)
plt.title("Distribusi Label NER (Before Training)")
plt.show()

"""**Penjelasan insight:** Dari grafik visualisasi di atas mengenai distribusi label NER sebelum training, diperoleh beberapa insight di antaranya ialah sebagai berikutZ:
1. Label O mendominasi secara masif dibandingkan seluruh label entitas lainnya. Ini menunjukkan bahwa sebagian besar token dalam dataset tidak termasuk entitas bernama. Kondisi ini sangat umum pada task NER, namun pada grafik ini tingkat dominasinya tergolong tinggi. Sedemikian sehingga model berpotensi bias ke label O, akurasi overall bisa terlihat tinggi, tetapi performa pada entitas penting bisa rendah, precision ataupun recall untuk label entitas berisiko tidak stabil.

2. Adanya distribusi entitas tidak merata antar kela, yaitu:
    - PER (Person) dan ORG (Organization) relatif lebih banyak dibandingkan entitas lain.
    - LOC (Location) berada di tingkat menengah.
    - DATE adalah entitas paling sedikit, baik pada prefix B- maupun I-.

    Sehingga model cenderung belajar lebih baik pada PER dan ORG, prediksi DATE kemungkinan lemah (low recall), karena sangat minim contoh, dan evaluasi per-label (macro F1) menjadi penting, bukan hanya micro F1.


3. Pola BIO konsisten, tetapi jumlah I- lebih kecil untuk setiap entitas label B- lebih banyak daripada I-, yang menandakan sebagian besar entitas terdiri dari satu token atau entitas multi-token relatif jarang. Sehingga model bisa kesulitan mempelajari transisi B → I, khususnya untuk entitas panjang.

"""

sentence_lengths = [len(s) for s in train_texts]

plt.figure()
sns.histplot(sentence_lengths, bins=30)
plt.title("Distribusi Panjang Kalimat")
plt.xlabel("Jumlah Token")
plt.show()

"""**Penjelasan insight:** Berdasarkan grafik visualisasi di atas mengenai distribusi panjang kalimat, diperoleh beberapa insight yaitu sebagai berikut:
1. Mayoritas kalimat berukuran pendek-menengah. Sebagian besar kalimat berada di rentang 10-30 token. Ini menunjukkan dataset didominasi oleh kalimat yang relatif ringkas.

2. Puncak distribusi sekitar 15-25 token. Rentang ini adalah yang paling sering muncul, sehingga bisa dianggap sebagai panjang kalimat “normal” dalam dataset.

3. Kalimat sangat panjang jumlahnya sedikit. Kalimat dengan lebih dari 40 token semakin jarang, dan hanya sedikit yang mencapai di atas 60 token.

4. Distribusi condong ke kanan (right-skewed).Artinya, ada ekor panjang di sisi kanan: sebagian kecil kalimat sangat panjang, tetapi tidak mendominasi data.

5. Panjang maksimum input model (misalnya 50 atau 64 token) sudah mencakup hampir seluruh data tanpa banyak pemotongan (truncation).

# Modeling - Fine-tuning BERT Hugging Face Model
"""

from transformers import (
    AutoTokenizer,
    AutoModelForTokenClassification,
    TrainingArguments,
    Trainer,
    DataCollatorForTokenClassification
)

model_name = "bert-base-multilingual-cased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

label_list = sorted(set(l for seq in train_labels for l in seq))

label2id = {label: i for i, label in enumerate(label_list)}
id2label = {i: label for label, i in label2id.items()}

print("Label list:", label_list)

model = AutoModelForTokenClassification.from_pretrained(
    model_name,
    num_labels=len(label2id),
    id2label=id2label,
    label2id=label2id
)

def tokenize_and_align_labels(texts, labels):
    tokenized = tokenizer(
        texts,
        truncation=True,
        padding=True,
        is_split_into_words=True
    )

    aligned_labels = []

    for i, label_seq in enumerate(labels):
        word_ids = tokenized.word_ids(batch_index=i)
        prev_word_id = None
        label_ids = []

        for word_id in word_ids:
            if word_id is None:
                label_ids.append(-100)
            elif word_id != prev_word_id:
                label_ids.append(label2id[label_seq[word_id]])
            else:
                label_ids.append(
                    label2id[label_seq[word_id].replace("B-", "I-")]
                )
            prev_word_id = word_id

        aligned_labels.append(label_ids)

    tokenized["labels"] = aligned_labels
    return tokenized

from datasets import Dataset, DatasetDict

train_dataset = Dataset.from_dict(
    tokenize_and_align_labels(train_texts, train_labels)
)
val_dataset = Dataset.from_dict(
    tokenize_and_align_labels(val_texts, val_labels)
)
test_dataset = Dataset.from_dict(
    tokenize_and_align_labels(test_texts, test_labels)
)

dataset = DatasetDict({
    "train": train_dataset,
    "validation": val_dataset,
    "test": test_dataset
})

from transformers import EvalPrediction

def compute_metrics(p: EvalPrediction):
    predictions = np.argmax(p.predictions, axis=2)
    labels = p.label_ids

    true_labels = [
        [id2label[l] for l in label if l != -100]
        for label in labels
    ]

    true_predictions = [
        [id2label[p] for p, l in zip(pred, label) if l != -100]
        for pred, label in zip(predictions, labels)
    ]

    return {
        "precision": precision_score(true_labels, true_predictions),
        "recall": recall_score(true_labels, true_predictions),
        "f1": f1_score(true_labels, true_predictions)
    }

args = TrainingArguments(
    output_dir="./ner-model",
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=3e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=7,
    weight_decay=0.01,
    warmup_ratio=0.1,
    lr_scheduler_type="linear",
    logging_steps=50,
    load_best_model_at_end=True,
    metric_for_best_model="f1",
    report_to="none",
    seed=SEED
)

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=dataset["train"],
    eval_dataset=dataset["validation"],
    tokenizer=tokenizer,
    data_collator=DataCollatorForTokenClassification(tokenizer),
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]
)

trainer.train()

"""**Penjelasan insight:** Berdasarkan output training model BERT di atas untuk NER analysis, diperoleh bahwa:
1. Model benar-benar belajar (training loss turun konsisten), yang ditunjukkan dengan training loss turun dari 0.238 menjadi 0.038. Hal ini menunjukkan model semakin tahu pattern data NER (PER, LOC, ORG, DATE), serta tidak ada lonjakan loss di tengan epoch yang ditandai dengan proses training stabil.

2. Validation loss relatif stabil (tidak overfitting parah), yang ditunjukkan dengan validation loss berada di kisaran 0.16 - 0.19. Setelah epoch 3–4, validation loss tidak membaik signifikan, bahkan sedikit naik di epoch akhir.

3. Precision, Recall, dan F1-score meningkat konsisten. Recall lebih tinggi dari precision, sehingga model lebih berani mendeteksi entitas. Untuk F1-score naik konsisten, sehingga kualitas prediksi makin seimbang dan akurat.

4. Epoch terbaik ada di epoch terakhir (7) yang ditandai dengan F1-score tertinggi di epoch 7: 0.7926, precision dan recall juga paling baik di epoch ini. Model belum overfitting parah, dan epoch 7 adalah checkpoint terbaik.


"""

predictions = trainer.predict(test_dataset)
logits = predictions.predictions
pred_ids = np.argmax(logits, axis=-1)

"""## Model Evaluation"""

preds, labels, _ = trainer.predict(dataset["test"])
preds = np.argmax(preds, axis=2)

true_labels = [
    [id2label[l] for l in lab if l != -100]
    for lab in labels
]

true_preds = [
    [id2label[p] for p, l in zip(pr, lab) if l != -100]
    for pr, lab in zip(preds, labels)
]

print(classification_report(true_labels, true_preds))

"""**Penjelasan insight:** Berdasarkan output classification report tersebut diperoleh beberapa insight yaiut:
* PER (Person) adalah entitas yang paling akurat dikenali. Precision, recall, dan F1 mendekati 0.9, artinya nama orang terdeteksi dengan sangat baik dan jarang salah.

* LOC (Location) juga memiliki performa stabil dan kuat. Precision dan recall sama-sama 0.84, menunjukkan model konsisten mengenali lokasi tanpa banyak false positive atau miss.

* ORG (Organization) performanya cukup baik tapi masih bisa ditingkatkan. Recall lebih tinggi dari precision, sehingga model cukup sering menangkap organisasi, tetapi masih ada salah klasifikasi.

* DATE adalah entitas paling lemah
F1 hanya 0.46, menandakan model sering melewatkan tanggal, atau salah membedakan DATE dengan entitas lain.

* Micro average (F1 = 0.80) menunjukkan performa keseluruhan model cukup kuat pada level token.

* Macro average lebih rendah (0.73) karena performa DATE yang tertinggal dibanding entitas lain.

* Weighted average tinggi (0.80) karena kelas dengan data besar (PER, LOC) performanya bagus.

Model NER sudah sangat baik untuk PER dan LOC, cukup baik untuk ORG, tetapi perlu perbaikan khusus untuk DATE (misalnya dengan data tambahan atau aturan khusus).

# Analisis Hasil Prediksi

## Entitas yang Diprediksi Benar
"""

true_preds_from_model = [
    [id2label[p] for p, l in zip(pred, label) if l != -100]
    for pred, label in zip(pred_ids, test_dataset["labels"])
]

def show_correct_predictions(texts, true_labels, pred_labels, n=5):
    count = 0

    for sent, true_seq, pred_seq in zip(texts, true_labels, pred_labels):
        for token, t, p in zip(sent, true_seq, pred_seq):
            if t == p and t != "O":
                print("Kalimat :", " ".join(sent))
                print("Token   :", token)
                print("Label   :", t)
                print("-" * 50)
                count += 1
                break

        if count >= n:
            break

show_correct_predictions(
    test_texts,
    test_labels,
    true_preds_from_model
)

"""**Penjelasan insight:** Berdasarkan output correct predictions di atas diperoleh bahwa:
* Entitas lokasi eksplisit terdeteksi dengan sangat baik, contoh: jakarta, athena. Menunjukkan model kuat mengenali nama kota/negara yang umum.

* Nama orang dikenali konsisten, termasuk multi-token
    - Contoh: nugroho notosutanto, tyson
    - Label B-PER / I-PER sudah digunakan dengan benar, berarti boundary entitas cukup rapi.

* Model mampu menangani konteks berita panjang
    - Kalimat kompleks dan panjang tetap menghasilkan prediksi entitas yang tepat
    - Ini menunjukkan model tidak hanya menghafal pola pendek.

* Kasus boundary label (B- vs I-) sudah cukup baik
    - Contoh: I-PER pada “notosutanto”, I-LOC pada “athena”
    - Artinya model memahami kelanjutan entitas, bukan hanya awalnya.

* Masih ada error semantik minor (wajar)
    - Contoh: mukernas → B-DATE (seharusnya ORG)- Ini konsisten dengan evaluasi sebelumnya bahwa:
        - DATE dan ORG masih sering tertukar
        - Entitas abstrak lebih sulit dibanding nama orang/lokasi
  
Model NER yang dibangun telah mampu mengenali entitas PER dan LOC dengan baik, termasuk pada kalimat panjang dan kompleks. Model juga menunjukkan pemahaman yang cukup baik terhadap batas entitas (B/I tagging). Namun, kesalahan masih ditemukan pada entitas yang bersifat abstrak seperti ORG dan DATE, yang menunjukkan perlunya peningkatan data atau fitur tambahan untuk kelas tersebut.

## Entitas yang Salah Prediksi
"""

def show_wrong_predictions(texts, true_labels, pred_labels, n=5):
    count = 0
    for sent, t_seq, p_seq in zip(texts, true_labels, pred_labels):
        for token, t, p in zip(sent, t_seq, p_seq):
            if t != p and t != "O":
                print("Kalimat :", " ".join(sent))
                print("Token   :", token)
                print("True    :", t)
                print("Pred    :", p)
                print("-"*50)
                count += 1
                break
        if count >= n:
            break

show_wrong_predictions(test_texts, true_labels, true_preds)

"""**Penjelasan insight:** Untuk wrong prediction diperoleh beberapa insight yaitu:
* Kebingungan antara PER dan ORG masih cukup sering terjadi. Contohnya pada token teamster, yang seharusnya diberi label B-PER, tetapi oleh model diprediksi sebagai B-ORG. Hal ini menunjukkan bahwa model masih kesulitan membedakan entitas individu dan kelompok atau organisasi ketika konteks kalimat tidak memberikan petunjuk yang cukup kuat.

* Beberapa entitas ORG tidak berhasil dikenali dan justru diberi label O. Contohnya pada token institute dan tribunnews, yang seharusnya diklasifikasikan sebagai organisasi, namun tidak terdeteksi sebagai entitas. Ini mengindikasikan bahwa variasi nama organisasi dalam data masih belum sepenuhnya terwakili sehingga model cenderung melewatkan entitas tersebut.

* Masih ditemukan kesalahan pada penentuan batas entitas (boundary error). Contohnya token heart yang seharusnya merupakan lanjutan entitas (I-PER), tetapi diprediksi sebagai awal entitas (B-PER). Hal ini menunjukkan bahwa meskipun model dapat mengenali entitas secara umum, konsistensi dalam menentukan awal dan kelanjutan entitas masih perlu ditingkatkan.

* Terdapat pula prediksi keliru pada kata umum yang sebenarnya tidak memiliki makna entitas. Contohnya token dan yang dilabeli B-PER, padahal konteksnya tidak merujuk pada entitas tertentu. Kesalahan ini mengindikasikan bahwa model masih terlalu mengandalkan pola lokal tanpa memahami konteks kalimat secara menyeluruh.

## Predict NER dari kalimat bebas
"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

def predict_ner(sentence):
    words = sentence.split()

    encoding = tokenizer(
        words,
        return_tensors="pt",
        is_split_into_words=True,
        truncation=True
    )

    word_ids = encoding.word_ids()

    encoding = {k: v.to(device) for k, v in encoding.items()}

    with torch.no_grad():
        outputs = model(**encoding)

    preds = torch.argmax(outputs.logits, dim=2).squeeze().tolist()

    results = []
    prev_word_id = None

    for word_id, pred_id in zip(word_ids, preds):
        if word_id is None or word_id == prev_word_id:
            continue
        label = id2label[pred_id]
        results.append((words[word_id], label))
        prev_word_id = word_id

    return results

def pretty_ner(sentence):
    results = predict_ner(sentence)
    entities = []
    current = []

    for token, label in results:
        if label.startswith("B-"):
            if current:
                entities.append(current)
            current = [(token, label)]
        elif label.startswith("I-") and current:
            current.append((token, label))
        else:
            if current:
                entities.append(current)
                current = []

    if current:
        entities.append(current)

    for ent in entities:
        text = " ".join(t for t,_ in ent)
        etype = ent[0][1].split("-")[1]
        print(f"{text} -> {etype}")

pretty_ner("Ariana Grande berkunjung ke Jakarta")

"""**Penjelasan insight:** Hasil pengujian menggunakan kalimat bebas menunjukkan bahwa model mampu mengenali entitas dengan pola yang jelas dan umum secara sangat baik. Nama Ariana Grande berhasil diklasifikasikan sebagai entitas PER, yang menandakan bahwa model telah mempelajari pola penulisan nama orang, termasuk nama internasional yang sering muncul dalam data. Sementara itu, Jakarta berhasil dikenali sebagai entitas LOC, menunjukkan kemampuan model dalam mengidentifikasi nama lokasi yang populer dan memiliki representasi kuat dalam data latih. Insight ini mengindikasikan bahwa model memiliki generalisasi yang baik terhadap input di luar dataset uji, khususnya untuk entitas dengan bentuk eksplisit dan tidak ambigu.

## Visualisasi setelah training
"""

rows = []

for t_seq, p_seq in zip(true_labels, true_preds):
    for t, p in zip(t_seq, p_seq):
        if t != "O":
            rows.append({"True": t, "Pred": p})

df_err = pd.DataFrame(rows)

plt.figure(figsize=(12,6))
sns.countplot(data=df_err, x="True", hue="Pred")
plt.xticks(rotation=90)
plt.title("Entity Prediction Comparison (After Training)")
plt.xlabel("True Entity")
plt.ylabel("Count")
plt.legend(bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.show()

"""**Penjelasan insight:** Berdasarkan grafik Entity Prediction Comparison (After Training), terlihat bahwa model memiliki performa yang paling kuat pada entitas PER dan LOC, terutama dalam mengenali token lanjutan (I-PER dan I-LOC) yang jumlah prediksinya paling dominan dan selaras dengan label sebenarnya. Hal ini menunjukkan bahwa model cukup konsisten dalam mengikuti konteks berurutan ketika sebuah entitas sudah terdeteksi. Untuk entitas ORG, model cenderung lebih baik mengenali bagian lanjutan (I-ORG) dibandingkan awal entitas (B-ORG), yang mengindikasikan bahwa model sering “menangkap” organisasi setelah konteksnya terbentuk, tetapi masih kurang tegas dalam mendeteksi awal kemunculannya. Sementara itu, entitas DATE memiliki distribusi prediksi yang paling tidak seimbang, dengan kecenderungan kesalahan antara B-DATE dan I-DATE, yang menegaskan bahwa model masih kesulitan memahami batas dan konteks temporal secara konsisten. Secara keseluruhan, grafik ini menguatkan hasil evaluasi sebelumnya bahwa model sudah sangat baik pada entitas yang eksplisit dan sering muncul seperti PER dan LOC, cukup stabil pada ORG, namun masih membutuhkan perbaikan pada entitas DATE, baik dari sisi data maupun penentuan boundary."""

entity_acc = (
    df_err.assign(correct=df_err["True"] == df_err["Pred"])
          .groupby(df_err["True"].str.split("-").str[-1])["correct"]
          .mean()
)

plt.figure(figsize=(8,5))
sns.barplot(x=entity_acc.index, y=entity_acc.values)
plt.title("Accuracy per Entity (After Training)")
plt.ylabel("Accuracy")
plt.xlabel("Entity")
plt.ylim(0,1)
plt.show()

"""**Penjelasan insight:** Berdasarkan grafik Accuracy per Entity (After Training), terlihat perbedaan performa yang cukup jelas antar jenis entitas. Entitas PER memiliki akurasi tertinggi, yang menunjukkan bahwa model sangat andal dalam mengenali nama orang. Hal ini wajar karena pola nama orang cenderung konsisten dan sering muncul dalam data latih. Entitas LOC juga menunjukkan akurasi yang tinggi, menandakan bahwa nama lokasi relatif mudah dikenali oleh model karena biasanya bersifat eksplisit dan kontekstual. Sementara itu, entitas ORG memiliki akurasi sedikit lebih rendah dibanding LOC dan PER, yang mengindikasikan bahwa model masih mengalami kesulitan membedakan organisasi dari entitas lain, terutama ketika nama organisasi memiliki bentuk yang bervariasi atau ambigu. Entitas DATE memiliki akurasi paling rendah, yang menunjukkan bahwa informasi temporal masih menjadi tantangan bagi model, baik dalam mengenali format tanggal maupun dalam membedakan DATE dari entitas atau token lain. Secara keseluruhan, grafik ini menegaskan bahwa model sudah sangat baik pada entitas yang konkret dan sering muncul (PER dan LOC), cukup baik pada ORG, namun masih memerlukan peningkatan khusus untuk entitas DATE.

# Recommendation Action

Berdasarkan hasil evaluasi model Named Entity Recognition (NER) yang telah dilakukan, terdapat beberapa rekomendasi pengembangan yang dapat dilakukan ke depannya:

1. **Penggunaan Model Pra-latih yang Lebih Spesifik Bahasa Indonesia**  
   Model `bert-base-multilingual-cased` sudah memberikan performa yang cukup baik, terutama pada entitas PER dan LOC. Namun, performa dapat ditingkatkan dengan menggunakan model yang lebih spesifik untuk Bahasa Indonesia seperti IndoBERT atau model NER yang telah di-pretrain pada domain berita lokal.

2. **Penambahan dan Penyeimbangan Data Latih**  
   Entitas DATE memiliki performa yang relatif lebih rendah dibandingkan entitas lainnya. Hal ini mengindikasikan adanya ketidakseimbangan jumlah data antar entitas. Penambahan data atau teknik data augmentation dapat membantu meningkatkan performa pada entitas minoritas.

3. **Hyperparameter Tuning Lebih Lanjut**  
   Eksperimen lanjutan seperti penyesuaian learning rate, jumlah epoch, batch size, serta penggunaan early stopping yang lebih optimal berpotensi meningkatkan generalisasi model.

4. **Eksplorasi Skema Labeling yang Lebih Konsisten**  
   Peningkatan konsistensi pada skema BIO tagging, khususnya untuk entitas multi-token, dapat membantu model memahami batas entitas dengan lebih baik.

5. **Evaluasi pada Data Dunia Nyata**  
   Model dapat diuji lebih lanjut menggunakan kalimat bebas di luar dataset untuk melihat robustness model dalam skenario penggunaan nyata.

# Save Model & Load Model
"""

trainer.save_model("./final-ner-model")
tokenizer.save_pretrained("./final-ner-model")

"""# Reflection Question
1. Berikan analisis terhadap hasil training berdasarkan hasil yang didapatkan di step 4 dan 5.

    Jawab: Berdasarkan hasil evaluasi model NER menggunakan bert-base-multilingual-cased, diperoleh:
    - micro F1-score sebesar 0.80 dan weighted F1-score sebesar 0.80, yang menunjukkan bahwa model secara keseluruhan memiliki performa yang baik dalam mengenali entitas pada data uji. Nilai recall micro (0.82) yang lebih tinggi dibanding precision (0.78) mengindikasikan bahwa model cenderung lebih baik dalam mendeteksi entitas, meskipun masih menghasilkan beberapa prediksi keliru.

    - Performa terbaik ditunjukkan oleh entitas PERSON (PER) dengan F1-score sebesar 0.89, diikuti oleh LOCATION (LOC) dengan F1-score sebesar 0.84. Hal ini menunjukkan bahwa model mampu menangkap pola kontekstual dan linguistik yang kuat pada entitas yang bersifat eksplisit dan sering muncul dalam data. Entitas ORGANIZATION (ORG) menunjukkan performa menengah dengan F1-score sebesar 0.74, yang mengindikasikan masih adanya kebingungan antara ORG dan entitas lain, terutama pada nama organisasi yang memiliki bentuk atau konteks yang ambigu.

    - Entitas dengan performa terendah adalah DATE, dengan F1-score sebesar 0.46. Rendahnya nilai precision (0.43) dan recall (0.50) pada kelas DATE menunjukkan bahwa model masih kesulitan mengenali dan membedakan ekspresi temporal dari konteks kalimat. Hal ini juga kemungkinan dipengaruhi oleh jumlah data DATE yang relatif lebih sedikit (137) dibandingkan kelas lainnya, sehingga model kurang terpapar pada variasi pola tanggal yang beragam.


2. Menurut anda, bagaimana cara yang dapat dilakukan untuk menaikkan akurasi dari model anda?

    Jawab: Berdasarkan hasil yang diperoleh, beberapa langkah yang dapat dilakukan untuk meningkatkan performa model adalah:
    - Menambah dan menyeimbangkan data pada entitas DATE. Performa DATE yang rendah sangat mungkin disebabkan oleh ketimpangan distribusi data. Penambahan contoh ekspresi tanggal yang beragam (format numerik, teks, singkatan) dapat membantu model belajar pola temporal dengan lebih baik.

    - Eksperimen hyperparameter lanjutan. Penyesuaian learning rate yang lebih kecil, penambahan epoch dengan mekanisme early stopping, atau penggunaan batch size yang lebih besar dapat meningkatkan stabilitas training.

    - Menggunakan model pre-trained yang lebih spesifik bahasa atau domain. Model multilingual bersifat umum. Menggunakan model berbasis Bahasa Indonesia atau domain-spesifik berpotensi meningkatkan pemahaman konteks lokal.

    - Analisis dan perbaikan error antar-entitas. Kesalahan prediksi ORG dan DATE dapat dikurangi dengan melakukan analisis confusion antar kelas dan memperbaiki label ambigu pada data training.

3. Berdasarkan workflow yang telah anda alami dari data preparation hingga evaluation, apa hal sulit yang anda rasakan? dan apa yang bisa di-improve dari workflow tersebut?

    Jawab: Tantangan utama dalam workflow yang dijalani adalah penyelarasan label BIO dengan hasil tokenisasi subword pada model transformer. Kesalahan pada tahap ini, seperti penanganan token dengan label -100, dapat berdampak langsung pada hasil evaluasi dan analisis kualitatif. Selain itu, ketidakseimbangan distribusi label juga menjadi kendala utama, terutama pada entitas DATE, yang mempengaruhi kemampuan model dalam melakukan generalisasi. Workflow ini dapat ditingkatkan dengan melakukan validasi otomatis terhadap alignment token dan label, analisis error per entitas secara lebih sistematis, serta eksperimen hyperparameter yang dirancang secara terstruktur. Dokumentasi pipeline yang lebih modular dan reusable juga akan mempermudah proses eksperimen dan evaluasi di tahap selanjutnya.


Secara keseluruhan, model NER yang ditraining telah menunjukkan performa yang baik dengan kemampuan generalisasi yang kuat pada entitas PERSON dan LOCATION. Meskipun masih terdapat kelemahan pada entitas DATE dan sebagian pada ORGANIZATION, hasil yang diperoleh sudah memenuhi tujuan pembelajaran dan memberikan pemahaman yang komprehensif mengenai tantangan serta potensi pengembangan model NER berbasis transformer.
"""